{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deal_sent_classify.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3bc5fadb26dd4a5bbdd026318d627219": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7c837b26715c48fc8359598bdf6dbeb5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_03ae13387d12403da8b6ea0b42696340",
              "IPY_MODEL_e72819fdd80a49f98bf49a4964b35c56"
            ]
          }
        },
        "7c837b26715c48fc8359598bdf6dbeb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "03ae13387d12403da8b6ea0b42696340": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0c02487981a948c5bfd87415dc06f877",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_637898c1ff104e388e08172bdbf09a67"
          }
        },
        "e72819fdd80a49f98bf49a4964b35c56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_676e4c8e4c38401c9acb5fe1ae817807",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 232k/232k [00:00&lt;00:00, 892kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e85ad047ccbb4350aa3bf9000d8a6603"
          }
        },
        "0c02487981a948c5bfd87415dc06f877": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "637898c1ff104e388e08172bdbf09a67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "676e4c8e4c38401c9acb5fe1ae817807": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e85ad047ccbb4350aa3bf9000d8a6603": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vaibhav-rj/vaibhav-rj/blob/master/deal_sent_classify.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bs4fN65bGu48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "outputId": "b1af2a49-7220-4efc-b6ed-84d5154c345c"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wckQWWtX8cfu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3c12017e-126e-47c9-be57-0b401b5d4fa3"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_w5cZH2IbYd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        },
        "outputId": "f7fa4b03-e2a7-437d-e9d3-cdbe55efc618"
      },
      "source": [
        "!pip3 install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ee/fc/bd726a15ab2c66dc09306689d04da07a3770dad724f0883f0a4bfb745087/transformers-2.4.1-py3-none-any.whl (475kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 481kB 10.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Collecting tokenizers==0.0.11\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/36/7af38d572c935f8e0462ec7b4f7a46d73a2b3b1a938f50a5e8132d5b2dc5/tokenizers-0.0.11-cp36-cp36m-manylinux1_x86_64.whl (3.1MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.1MB 75.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.9)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 870kB 62.6MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.0MB 47.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.2)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.9 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.9->boto3->transformers) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.9->boto3->transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=de713faf80304f61458b4887fcf323f2f1e2ab0c835faa515d282296be2a6c15\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.0.11 transformers-2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_UFR86Hzq7Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "02d30930-db24-4863-810f-7202a95dca75"
      },
      "source": [
        "# Mount Google Drive to this Notebook instance.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2fCCpUwIkCL"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/drive/My Drive/Team restricted/Colab Notebooks/deal_data.csv\")\n",
        "#df = pd.read_csv(\"/content/gdrive/My Drive/Colab Notebooks/deal_data .csv\")\n",
        "#df = pd.read_csv(uploaded['deal_data .csv'])\n",
        "df.tail()\n",
        "\n",
        "ls=[]\n",
        "for i in range(df['link'].count()):\n",
        "    d=dict(df.iloc[i])\n",
        "    d['ID']='id'+str(i).zfill(4)\n",
        "    ls.append(d)\n",
        "    #count+=1\n",
        "\n",
        "df1=pd.DataFrame(ls)\n",
        "df1.tail()\n",
        "\n",
        "# Creating train dataframe according to BERT\n",
        "#df_bert_train = pd.DataFrame({'id':df1['ID'], 'label':df1['LABEL'], 'alpha':['a']*df1.shape[0], 'sentence':df1['SENTENCE'].replace(r'\\n',' ',regex=True)})\n",
        "df_bert_train_one = df1[(df1['LABEL'] == 1) & (df1['SENTENCE'].str.len() <512)]\n",
        "df_bert_train_zero = df1[(df1['LABEL'] == 0) & (df1['SENTENCE'].str.len() <512)]\n",
        "#df_bert_train, df_bert_dev = train_test_split(df_bert, test_size=0.01)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLCqw0PtmtWg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "84305c9b-322a-43f6-c66b-9b195dd03d0e"
      },
      "source": [
        "df_bert_train_zero.count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "link          866\n",
              "SENTENCE      866\n",
              "LABEL         866\n",
              "Unnamed: 3      0\n",
              "ID            866\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sczv_ArjoLU7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "9dd56e5e-e0f4-4c18-8e63-dce92b8bb035"
      },
      "source": [
        "df_bert_train_one.count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "link          437\n",
              "SENTENCE      437\n",
              "LABEL         437\n",
              "Unnamed: 3      1\n",
              "ID            437\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBqGT4b9pIi6"
      },
      "source": [
        "df_bert_train =[]\n",
        "for i in range(df_bert_train_zero['link'].count()//2):\n",
        "  j = 2*i\n",
        "  df_bert_train.append(dict(df_bert_train_one.iloc[i]) )\n",
        "\n",
        "  [df_bert_train.append(dict(df_bert_train_zero.iloc[k])) for k in range(j,j+2)]\n",
        "\n",
        "df_bert_train = pd.DataFrame(df_bert_train)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQbn7UDLrLuQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "a7b0bb3e-8598-453b-8a0b-96227a306b62"
      },
      "source": [
        "df_bert_train.count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "link          1299\n",
              "SENTENCE      1299\n",
              "LABEL         1299\n",
              "Unnamed: 3       1\n",
              "ID            1299\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dPTOXxAI5jN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "outputId": "e96687cb-7f46-4a96-acf3-a69562ba450e"
      },
      "source": [
        "# Report the number of sentences.\n",
        "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "df_bert_train.head(9)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training sentences: 1,390\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>link</th>\n",
              "      <th>SENTENCE</th>\n",
              "      <th>LABEL</th>\n",
              "      <th>Unnamed: 3</th>\n",
              "      <th>ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>http://www.fiercepharma.com/pharma/doj-s-price...</td>\n",
              "      <td>Allergan, which sold its generics division to ...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>id0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>http://www.fiercepharma.com/pharma/pfizer-cons...</td>\n",
              "      <td>According to a Reuters exclusive, unnamed sour...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>id0003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>http://www.fiercepharma.com/pharma/pfizer-cons...</td>\n",
              "      <td>Take out charges for acquisitions and other on...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>id0004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>http://www.fiercepharma.com/pharma/pfizer-cons...</td>\n",
              "      <td>Merck ($MRK) sold its consumer health unit in ...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>id0001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>http://www.fiercepharma.com/pharma/valeant-sla...</td>\n",
              "      <td>Valeant reported that its revenues during the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>id0006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>http://www.fiercepharma.com/pharma/valeant-sla...</td>\n",
              "      <td>The dire report sent some analysts on a search...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>id0007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>http://www.fiercepharma.com/pharma/pfizer-cons...</td>\n",
              "      <td>But the unit drew a lot of interest, and Bayer...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>id0002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>http://www.fiercepharma.com/pharma/regeneron-s...</td>\n",
              "      <td>But Regeneronâ€™s collaboration with French phar...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>id0010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>http://www.fiercepharma.com/marketing/former-s...</td>\n",
              "      <td>To make sure they're not shortchanged, theyâ€™re...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>id0013</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                link  ...      ID\n",
              "0  http://www.fiercepharma.com/pharma/doj-s-price...  ...  id0000\n",
              "1  http://www.fiercepharma.com/pharma/pfizer-cons...  ...  id0003\n",
              "2  http://www.fiercepharma.com/pharma/pfizer-cons...  ...  id0004\n",
              "3  http://www.fiercepharma.com/pharma/pfizer-cons...  ...  id0001\n",
              "4  http://www.fiercepharma.com/pharma/valeant-sla...  ...  id0006\n",
              "5  http://www.fiercepharma.com/pharma/valeant-sla...  ...  id0007\n",
              "6  http://www.fiercepharma.com/pharma/pfizer-cons...  ...  id0002\n",
              "7  http://www.fiercepharma.com/pharma/regeneron-s...  ...  id0010\n",
              "8  http://www.fiercepharma.com/marketing/former-s...  ...  id0013\n",
              "\n",
              "[9 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhHB8O9juZ51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dd793fa6-7d32-445a-e9f9-a28f3e8850c7"
      },
      "source": [
        "# Get the lists of sentences and their labels.\n",
        "sentences = df_bert_train.SENTENCE.values\n",
        "labels = df_bert_train.LABEL.values\n",
        "print(labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 0 0 ... 1 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eNLlVUkv0zr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "3bc5fadb26dd4a5bbdd026318d627219",
            "7c837b26715c48fc8359598bdf6dbeb5",
            "03ae13387d12403da8b6ea0b42696340",
            "e72819fdd80a49f98bf49a4964b35c56",
            "0c02487981a948c5bfd87415dc06f877",
            "637898c1ff104e388e08172bdbf09a67",
            "676e4c8e4c38401c9acb5fe1ae817807",
            "e85ad047ccbb4350aa3bf9000d8a6603"
          ]
        },
        "outputId": "31fbf049-efa3-40cd-c01a-a48f3c1c5122"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3bc5fadb26dd4a5bbdd026318d627219",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=231508, style=ProgressStyle(description_widâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RZYKU3gwBb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "47de4968-dccd-4d2e-ed12-9bbb17b358d3"
      },
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', sentences[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  Allergan, which sold its generics division to Teva for $40.5 billion\n",
            "Tokenized:  ['all', '##er', '##gan', ',', 'which', 'sold', 'its', 'generic', '##s', 'division', 'to', 'te', '##va', 'for', '$', '40', '.', '5', 'billion']\n",
            "Token IDs:  [2035, 2121, 5289, 1010, 2029, 2853, 2049, 12391, 2015, 2407, 2000, 8915, 3567, 2005, 1002, 2871, 1012, 1019, 4551]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9B2gAj74wLOb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "e7bf09b8-08cd-4bd9-f68f-8cf6c745419c"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "\n",
        "                        # This function also supports truncation and conversion\n",
        "                        # to pytorch tensors, but we need to do padding, so we\n",
        "                        # can't use these features :( .\n",
        "                        #max_length = 128,          # Truncate all sentences.\n",
        "                        #return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  Allergan, which sold its generics division to Teva for $40.5 billion\n",
            "Token IDs: [101, 2035, 2121, 5289, 1010, 2029, 2853, 2049, 12391, 2015, 2407, 2000, 8915, 3567, 2005, 1002, 2871, 1012, 1019, 4551, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfpsEiqAJo0E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dd014316-3194-4007-d19a-e9f00dab14d7"
      },
      "source": [
        "print(len(input_ids[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "21\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88BE-JOSwXp4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d24448a9-b33c-4914-f23b-c4e866269cdf"
      },
      "source": [
        "print('Max sentence length: ', max([len(sen) for sen in input_ids]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  135\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7obyEq_P7nGA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "ac4000d7-b3bf-477a-9d51-382bc7373a67"
      },
      "source": [
        "# We'll borrow the `pad_sequences` utility function to do this.\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Set the maximum sequence length.\n",
        "# I've chosen 64 somewhat arbitrarily. It's slightly larger than the\n",
        "# maximum training sentence length of 47...\n",
        "MAX_LEN = 256\n",
        "\n",
        "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
        "\n",
        "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "# Pad our input tokens with value 0.\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print('\\nDone.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Padding/truncating all sentences to 256 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKXKwNncRklW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "e6def6de-bd6d-4fa4-f507-f0e59a6bad41"
      },
      "source": [
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  Allergan, which sold its generics division to Teva for $40.5 billion\n",
            "Token IDs: [  101  2035  2121  5289  1010  2029  2853  2049 12391  2015  2407  2000\n",
            "  8915  3567  2005  1002  2871  1012  1019  4551   102     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVaw4Ub-7u0I"
      },
      "source": [
        "attention_masks = []\n",
        "\n",
        "# For each sentence...\n",
        "for sent in input_ids:\n",
        "    \n",
        "    # Create the attention mask.\n",
        "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
        "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    \n",
        "    # Store the attention mask for this sentence.\n",
        "    attention_masks.append(att_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "US8487t-SCiG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "a549c9e7-86e5-4f2a-cd58-538ae45d6c57"
      },
      "source": [
        "print('Original: ', sentences[0])\n",
        "print('Attention_masks: ', attention_masks[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  Allergan, which sold its generics division to Teva for $40.5 billion\n",
            "Attention_masks:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpmj58HQ796Z"
      },
      "source": [
        "# Use train_test_split to split our data into train and validation sets for\n",
        "# training\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use 90% for training and 10% for validation.\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
        "                                                            random_state=2018, test_size=0.1)\n",
        "# Do the same for the masks.\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
        "                                             random_state=2018, test_size=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1N6HpAJC8CN9"
      },
      "source": [
        "# Convert all inputs and labels into torch tensors, the required datatype \n",
        "# for our model.\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONrEekGp8Fjl"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here.\n",
        "# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n",
        "# 16 or 32.\n",
        "\n",
        "batch_size = 30\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2syk4S68p1T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "86e69d02-a671-4029-faa6-c48f677727f8"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Frrrma3u8tef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "outputId": "86d36a55-c9f9-4df0-dabf-6ecb6b48b57f"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (2, 768)\n",
            "classifier.bias                                                 (2,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Q3Bv6mt9BGR"
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AA-FVLTI9If1"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgjlXpi_9L1m"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGwU9UuU9PZZ"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0Toyg1o9TRG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "outputId": "9f3c7541-5f74-46da-9bb1-edf8eda00455"
      },
      "source": [
        "import random\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Store the average loss after each epoch so we can plot them.\n",
        "loss_values = []\n",
        "\n",
        "model.zero_grad()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    # Set our model to training mode (as opposed to evaluation mode)\n",
        "    model.train()\n",
        "        \n",
        "    # This training code is based on the `run_glue.py` script here:\n",
        "    # https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Put the model into training mode.    \n",
        "        model.train()\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "                \n",
        "        # Forward pass (evaluate the model on this training batch)\n",
        "        # `model` is of type: pytorch_pretrained_bert.modeling.BertForSequenceClassification\n",
        "        outputs = model(b_input_ids, \n",
        "                    token_type_ids=None, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)\n",
        "        \n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Accumulate the loss. `loss` is a Tensor containing a single value; \n",
        "        # the `.item()` function just returns the Python value from the tensor.\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "        # Clear out the gradients (by default they accumulate)\n",
        "        model.zero_grad()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    \n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put model in evaluation mode to evaluate loss on the validation set\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
        "        with torch.no_grad():        \n",
        "            # Forward pass, calculate logit predictions\n",
        "            # token_type_ids is for the segment ids, but we only have a single sentence here.\n",
        "            # See https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L258 \n",
        "            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "        \n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.58\n",
            "  Training epcoh took: 0:00:32\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.41\n",
            "  Training epcoh took: 0:00:32\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.80\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.31\n",
            "  Training epcoh took: 0:00:32\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.25\n",
            "  Training epcoh took: 0:00:32\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HH9ToGcZ-3Zx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "f7af8559-3b36-496e-feb0-b1b05aaab6b8"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(loss_values, 'b-o')\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Batch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvAAAAGaCAYAAABpIXfbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nOzdeVRUV7o28KcKCpB5KuZiEKUQkJko\ncQAVCCoaY8R2Cpq2jem0nW7vTSd6TUw+u3PtOMQkJibXdJtW2wFRUKMdBecJBURBFI0iaiEOpUyi\nMkTq+0OphIBAKXCqiue3lmuFfab3sBf6cPLWPiKVSqUCERERERHpBLHQBRARERERUfsxwBMRERER\n6RAGeCIiIiIiHcIAT0RERESkQxjgiYiIiIh0CAM8EREREZEOYYAnIuqmlixZArlcDqVS+UzH19bW\nQi6XY/78+R1cmWY2bNgAuVyO06dPC1oHEVFXMRS6ACKi7kwul7d7371798LNza0TqyEiIl3AAE9E\nJKBFixY1+frkyZNITk7Gb37zG4SFhTXZZmtr26HX/vOf/4w//vGPMDY2fqbjjY2NkZ+fDwMDgw6t\ni4iIWscAT0QkoJdffrnJ148ePUJycjKCg4ObbXsalUqFhw8fwtTUVKNrGxoawtDw+f4ZeNbwT0RE\nz4498EREOuTQoUOQy+XYsWMHVq9ejfj4ePTt2xf//ve/AQC5ubl49913ERcXh6CgIISGhmLy5MnY\nv39/s3O11APfOKZQKPDJJ59g0KBB6Nu3L1555RUcPXq0yfEt9cD/ciw7OxsTJ05EUFAQ+vfvj/nz\n5+Phw4fN6jh27BgSExPRt29fDBw4EH//+99x7tw5yOVyrFy58pm/V3fu3MH8+fMxePBgBAQEYMiQ\nIfjb3/6GysrKJvs9ePAAy5Ytw0svvYTAwEBERERg1KhRWLZsWZP99uzZg4kTJ6Jfv34IDAzEkCFD\n8Pbbb0OhUDxzjUREz4JP4ImIdNC3336Le/fu4dVXX4WdnR1kMhkAYNeuXVAoFBgxYgRcXFxQVlaG\ntLQ0vPnmm1i+fDni4uLadf7//u//hrGxMX73u9+htrYW//rXv/D73/8eGRkZcHR0bPP4M2fOYPfu\n3Rg3bhxGjx6NzMxMJCcnw8jICO+//756v8zMTMyYMQO2traYOXMmzM3NsXPnTmRlZT3bN+aJiooK\n/OY3v0FpaSkSExPh6+uLM2fO4N///jdOnDiBTZs2oUePHgCADz74ADt37sQrr7yC4OBg1NfX48qV\nKzh+/Lj6fEeOHMGsWbPg5+eHN998E+bm5rh16xaOHj2KkpIS9fefiKgrMMATEemg27dv44cffoC1\ntXWT8T//+c/NWmlee+01jB49Gl9//XW7A7yjoyO++OILiEQiAFA/yU9JScGsWbPaPP7ChQvYvHkz\n/Pz8AAATJ07E1KlTkZycjHfffRdGRkYAgIULF0IikWDTpk1wdnYGAEyaNAkTJkxoV51P880336Ck\npAQff/wxxo0bpx7v3bs3PvnkE/UvJCqVCvv27UNMTAwWLlz41PPt2bMHALB69WpYWFiox9vzvSAi\n6mhsoSEi0kGvvvpqs/AOoEl4f/jwIcrLy1FbW4sXXngBhYWFqKura9f5p06dqg7vABAWFgaJRIIr\nV6606/iIiAh1eG/Uv39/1NXV4caNGwCA69ev48KFC3jppZfU4R0AjIyMkJSU1K7rPE3j/ykYO3Zs\nk/EpU6bAwsICGRkZAACRSAQzMzNcuHABRUVFTz2fhYUFVCoVdu/ejUePHj1XbUREz4tP4ImIdJCn\np2eL47dv38ayZcuwf/9+lJeXN9t+79492NnZtXn+X7eEiEQiWFlZoaKiol31tdRS0vgLR0VFBTw8\nPFBSUgIA8PLyarZvS2PtpVKpUFpaiv79+0MsbvqcysjICO7u7uprA8C8efPwP//zPxgxYgQ8PDzQ\nr18/DB06FNHR0epfYqZOnYoDBw5g3rx5+Pvf/47w8HAMGjQII0aMgI2NzTPXSkT0LBjgiYh0UGP/\n9i89evQI06ZNQ0lJCZKSkuDv7w8LCwuIxWJs3LgRu3fvRkNDQ7vO/+vg20ilUj3X8Zqco6sMHz4c\n/fr1w6FDh5CVlYUjR45g06ZNiIyMxD/+8Q8YGhrC3t4eaWlpyM7OxrFjx5CdnY2//e1v+OKLL/DP\nf/4TAQEBQt8GEXUjDPBERHqioKAARUVF+K//+i/MnDmzybbGVWq0iaurKwCguLi42baWxtpLJBLB\n1dUVly9fRkNDQ5NfJurq6nDt2jW4u7s3OcbW1hZjxozBmDFjoFKp8L//+79Ys2YNDh06hKFDhwJ4\nvOxmZGQkIiMjATz+fo8bNw7/93//h+XLlz9zvUREmmIPPBGRnmgMqr9+wn327FkcPHhQiJJa5ebm\nBh8fH+zevVvdFw88Dtlr1qx5rnPHxMTg5s2b2Lp1a5Px9evX4969e4iNjQUA1NfXo7q6usk+IpEI\nffr0AQD1kpNlZWXNrtGrVy8YGRm1u62IiKij8Ak8EZGekMvl8PT0xNdff42qqip4enqiqKgImzZt\nglwux9mzZ4UusZk5c+ZgxowZGD9+PCZMmAAzMzPs3LmzyQdon8Wbb76J9PR0vP/++8jLy4NcLkdB\nQQFSU1Ph4+ODadOmAXjcjx8TE4OYmBjI5XLY2tpCoVBgw4YNsLGxQVRUFADg3XffRVVVFSIjI+Hq\n6ooHDx5gx44dqK2txZgxY57320BEpBEGeCIiPWFkZIRvv/0WixYtwpYtW1BbWwsfHx98+umnOHny\npFYG+AEDBmDlypVYtmwZvvnmG1hZWSEhIQExMTGYPHkyTExMnum81tbWSE5OxvLly7F3715s2bIF\ndnZ2mDJlCv74xz+qP0NgYWGBKVOmIDMzE4cPH8bDhw8hlUoRFxeHmTNnwtbWFgAwduxYbNu2Damp\nqSgvL4eFhQV69+6NFStWYNiwYR32/SAiag+RSts+TURERN3e9u3b8Ze//AVfffUVYmJihC6HiEir\nsAeeiIgE09DQ0Gxt+rq6OqxevRpGRkYIDw8XqDIiIu3FFhoiIhJMdXU1RowYgVGjRsHT0xNlZWXY\nuXMnLl68iFmzZrX4sioiou6OAZ6IiARjYmKCAQMGID09HXfu3AEA9OzZE3/9618xfvx4gasjItJO\n7IEnIiIiItIh7IEnIiIiItIhDPBERERERDqEPfAaKi+/j4aGru86srMzx9271W3vSF2Gc6KdOC/a\nh3OinTgv2odzop2EmBexWAQbG7OnbmeA11BDg0qQAN94bdIunBPtxHnRPpwT7cR50T6cE+2kbfPC\nFhoiIiIiIh3CAE9EREREpEMY4ImIiIiIdAgDPBERERGRDmGAJyIiIiLSIQzwREREREQ6hAGeiIiI\niEiHMMATEREREekQBngiIiIiIh3CN7FqucyzN5F6sAhlVbWwtTTG2ChvRPo7CV0WEREREQmEAV6L\nZZ69idU/nEfdTw0AgLtVtVj9w3kAYIgnIiIi6qbYQqPFUg8WqcN7o7qfGpB6sEigioiIiIhIaAzw\nWuxuVa1G40RERESk/xjgtZidpXGL4xamki6uhIiIiIi0BQO8Fhsb5Q0jw6ZTJAJw70E9Ug9dxqOG\nhpYPJCIiIiK9xQ+xarHGD6r+chWa0QO9cLGkEjuOXcFFRQXeGO0PG4uWn9QTERERkf5hgNdykf5O\niPR3glRqAaXyHgBgUKAL5DJrrE2/gI++y8KMUX4I8LITuFIiIiIi6gpsodFRA/o6Y/7UCFiaGmFZ\nch5baoiIiIi6CQZ4HeZib4b3p4ZjYKAzdhy7giUbTqP8HleoISIiItJnDPA6zlhigNdH9MHvEvqg\n+GYVPvouCwXFd4Uui4iIiIg6CQO8nngx4ElLjVljS00RW2qIiIiI9BADvB5xsTfD+0mNLTVXsZgt\nNURERER6hwFez/yypeYKW2qIiIiI9A4DvJ5iSw0RERGRfmKA12NsqSEiIiLSPwzweo4tNURERET6\nhQG+m2BLDREREZF+YIDvRthSQ0RERKT7GOC7mcaWmhkJfrh68x5baoiIiIh0jKGQF6+rq8Pnn3+O\nbdu2oaqqCr6+vpg9ezYiIyNbPW758uX48ssvm43b29vj6NGjTcbkcnmL5/joo48wceLEZy9ex0UG\nOMHT2QIrthZgWXIeRr7ogZcHesFAzN/piIiIiLSZoAF+zpw5SE9PR1JSEjw8PJCWloYZM2Zg7dq1\nCAkJafP4BQsWwMTERP31L//7lwYOHIjRo0c3GQsKCnq+4vWAs93jlpr1GT9ix7Gr+FFRiZmj/WFj\nYSx0aURERET0FIIF+Pz8fOzcuRNz587FtGnTAABjxoxBQkIClixZgnXr1rV5juHDh8PS0rLN/Xr2\n7ImXX375eUvWS40tNb7uNliz+wI++i4LM0b5IcDLTujSiIiIiKgFgvVL7Nq1CxKJBImJieoxY2Nj\njBs3DidPnsTt27fbPIdKpUJ1dTVUKlWb+9bU1KC2lh/YfJrIACfMnxbOVWqIiIiItJxgAb6wsBBe\nXl4wMzNrMh4YGAiVSoXCwsI2zxEdHY2wsDCEhYVh7ty5qKioaHG/zZs3Izg4GIGBgRg1ahQyMjI6\n5B70TWNLzaAgrlJDREREpK0Ea6FRKpVwdHRsNi6VSgGg1SfwlpaWeO211xAUFASJRILjx48jOTkZ\n586dQ0pKCoyMjNT7hoSEYMSIEXBzc8ONGzewZs0azJo1C0uXLkVCQkLH35iOM5YYYNrwPpDLftFS\nk+CHgJ5sqSEiIiLSBiJVe/pPOkFMTAx69eqFb775psm4QqFATEwMPvjgA0yZMqXd51u3bh0WLFiA\nv/71rxg/fvxT93vw4AESEhLw6NEjHDhwACKR6JnvQd8pbt3DJ2uycfXmPSQO643JL/nCwICr1BAR\nEREJSbAn8CYmJqivr2823tinbmys2UooEydOxOLFi5GZmdlqgDc1NcWECROwdOlSXL58Gd7e3hpd\n5+7dajQ0dP3vPFKpBZTKe116TRMxMGdyKDbs+REpey8i78JtzHw5gKvUPCHEnFDbOC/ah3OinTgv\n2odzop2EmBexWAQ7O/Onb+/CWpqQSqUttskolUoAgIODg0bnE4vFcHR0RGVlZZv7Ojs7A0C79u3u\nGltqZiT44eqtany4KgsFl/niJyIiIiKhCBbgfX19UVxcjPv37zcZz8vLU2/XRH19PW7cuAEbG5s2\n91UoFAAAW1tbja7RnTWuUmNlboRPN+Vhy0GuUkNEREQkBMECfHx8POrr65GSkqIeq6urQ2pqKkJD\nQ9UfcC0tLUVRUVGTY8vKypqd75///Cdqa2sxaNCgVvcrLy/H+vXr4ebmBk9Pzw66m+6hcZWawUHO\n2Jl5FYvXn+IqNURERERdTLAe+KCgIMTHx2PJkiVQKpVwd3dHWloaSktLsXDhQvV+7733HrKysnDh\nwgX12JAhQzBixAj4+PjAyMgIJ06cwO7duxEWFtZkZZl169Zh7969iI6OhouLC27duoXk5GSUlZXh\nq6++6tL71Re/XqXmw1VZeGMUV6khIiIi6iqCBXgAWLRoET777DNs27YNlZWVkMvlWLlyJcLCwlo9\nbtSoUcjNzcWuXbtQX18PV1dXvPXWW5g5cyYMDX++pZCQEOTm5iIlJQWVlZUwNTVFcHAwZs6c2eY1\nqHWRAU7wdLbAiq0F+HRTHkZGemDMIC8YiLlKDREREVFnEmwZSV3VnVahaY/a+kfYsOdHHMq7AR83\nq261So22zkl3x3nRPpwT7cR50T6cE+3EVWhI76hXqRnFVWqIiIiIugIDPHWISP/Hq9RYc5UaIiIi\nok7FAE8d5udValy4Sg0RERFRJ2GApw5lJDHAtOG+TVpqzrClhoiIiKjDMMBTp/hlS80yttQQERER\ndRgGeOo0bKkhIiIi6ngM8NSp2FJDRERE1LEY4KlLsKWGiIiIqGMwwFOX+XVLzSK21BARERFpjAGe\nutQvW2qusaWGiIiISGMM8CQIttQQERERPRsGeBJMY0tNVPDPLTVlVTVCl0VERESk1RjgSVBGEgNM\njf+5peaj77LZUkNERETUCgZ40gpsqSEiIiJqHwZ40hpsqSEiIiJqGwM8aZXGlpo3Rvnh2m221BAR\nERH9GgM8aaX+/k6YPzUc1ubGWLYpD5sPsKWGiIiICGCAJy32uKUmDFHBLvjPcbbUEBEREQEM8KTl\nWmqpyS9iSw0RERF1XwzwpBN+2VLzWQpbaoiIiKj7YoAnncGWGiIiIiIGeNIxbKkhIiKi7o4BnnQS\nW2qIiIiou2KAJ53FlhoiIiLqjhjgSaepW2pGs6WGiIiIugcGeNIL/f2c8OG0CLbUEBERkd5jgCe9\n4WRriveTwhD9pKXmE7bUEBERkR5igCe9YiQxQNKTlhoFW2qIiIhIDzHAk176dUtNyoFL+OkRW2qI\niIhI9zHAk976ZUvND8evYdEGttQQERGR7mOAJ73GlhoiIiLSNwzw1C00ttTYWLClhoiIiHSboAG+\nrq4OixcvxsCBAxEYGIjx48cjMzOzzeOWL18OuVze7M+AAQNa3D8lJQXDhw9H37598dJLL2HdunUd\nfSukA5xsTTHvNbbUEBERkW4zFPLic+bMQXp6OpKSkuDh4YG0tDTMmDEDa9euRUhISJvHL1iwACYm\nJuqvf/nfjTZu3IgPP/wQ8fHxeP3115GTk4MFCxagtrYWv/3tbzv0fkj7NbbU+LhbY/WuC/jou2z8\nLqEPAr3thS6NiIiIqF0EC/D5+fnYuXMn5s6di2nTpgEAxowZg4SEBCxZsqRdT8mHDx8OS0vLp26v\nqanBsmXLMGzYMHz++ecAgPHjx6OhoQFffvklEhMTYWFh0SH3Q7qlv58TPJ0s8fXWAnyWko/h/d3x\nyqCeMDRgVxkRERFpN8HSyq5duyCRSJCYmKgeMzY2xrhx43Dy5Encvn27zXOoVCpUV1dDpVK1uP3E\niROoqKjApEmTmoxPnjwZ9+/fx6FDh57vJkinsaWGiIiIdJFgAb6wsBBeXl4wMzNrMh4YGAiVSoXC\nwsI2zxEdHY2wsDCEhYVh7ty5qKioaLL93LlzAICAgIAm4/7+/hCLxert1H21vErNHaHLIiIiInoq\nwVpolEolHB0dm41LpVIAaPUJvKWlJV577TUEBQVBIpHg+PHjSE5Oxrlz55CSkgIjIyP1NYyMjGBt\nbd3k+Max9jzlp+6BLTVERESkKwQL8DU1NZBIJM3GjY2NAQC1tbVPPXbq1KlNvo6Pj0fv3r2xYMEC\nbN26FePHj2/1Go3Xae0aT2NnZ67xMR1FKmW/fmeSSi2w7L/s8Y9tBfgh8wqu3KzGX6aEQ2rTo9Vj\nSPtwXrQP50Q7cV60D+dEO2nbvAgW4E1MTFBfX99svDFUNwb59po4cSIWL16MzMxMdYA3MTFBXV1d\ni/vX1tZqfA0AuHu3Gg0NLffcdyap1AJK5b0uv253ND6qJzykZvjXrvN4e+n+p65SwznRTpwX7cM5\n0U6cF+3DOdFOQsyLWCxq9aGxYP0BUqm0xRYWpVIJAHBwcNDofGKxGI6OjqisrGxyjfr6+ma98XV1\ndaioqND4GtR99PNz/MWLn/L54iciIiLSGoIFeF9fXxQXF+P+/ftNxvPy8tTbNVFfX48bN27AxsZG\nPdanTx8AQEFBQZN9CwoK0NDQoN5O1BInW1O8nxSG6BDXx6vUrOcqNURERCQ8wQJ8fHw86uvrkZKS\noh6rq6tDamoqQkND1R9wLS0tRVFRUZNjy8rKmp3vn//8J2prazFo0CD1WP/+/WFtbY3169c32XfD\nhg0wNTXF4MGDO/KWSA9JDA2Q9JIcM0f7Q6GsxoersrhKDREREQlKsB74oKAgxMfHY8mSJVAqlXB3\nd0daWhpKS0uxcOFC9X7vvfcesrKycOHCBfXYkCFDMGLECPj4+MDIyAgnTpzA7t27ERYWhoSEBPV+\nJiYmePvtt7FgwQL86U9/wsCBA5GTk4Pt27fjnXfeafUlUES/1M/PEZ5OFljRuEpNP3e88WqQ0GUR\nERFRNyRYgAeARYsW4bPPPsO2bdtQWVkJuVyOlStXIiwsrNXjRo0ahdzcXOzatQv19fVwdXXFW2+9\nhZkzZ8LQsOktTZ48GRKJBKtWrcLevXvh7OyMefPmISkpqTNvjfSQ45OWmg17L+GHE9dw5VY1po/w\nha2lidClERERUTciUj3tNabUIq5CQwBw4twtrNl9HmKRCL9L8ENQr+ar1JAw+LOifTgn2onzon04\nJ9qJq9AQ6Yl+fo74bHY0bC1N8PnmfKTs5yo1RERE1DUY4ImekYvU/OdVak5wlRoiIiLqGgzwRM+h\npVVq8i5xlRoiIiLqPAzwRB2gn58jPpoWwZYaIiIi6nQM8EQdpHGVmiFsqSEiIqJOxABP1IEkhgZ4\n7SU53nzZHyVsqSEiIqJOwABP1Ale6OOID6dFwO5JS80mttQQERFRB2GAJ+okjrammPekpWbXiWv4\nZH0uW2qIiIjouTHAE3WiX7bUXFfeZ0sNERERPTcGeKIuwJYaIiIi6igM8ERdhC01RERE1BEY4Im6\nUEstNafZUkNEREQaYIAnEsAvW2q+YEsNERERaYABnkggLbXU3K1kSw0RERG1jgGeSEC/bqn56Du2\n1BAREVHrGOCJtABbaoiIiKi9GOCJtARbaoiIiKg9GOCJtAhbaoiIiKgtDPBEWuiFPo748HW21BAR\nEVFzDPBEWsrR5klLTShbaoiIiOhnDPBEWkxiaIDX4thSQ0RERD9jgCfSAeqWGqsnLTX72FJDRETU\nXTHAE+kIRxtTzHvtSUtNFltqiIiIuisGeCIdwpYaIiIiYoAn0kFsqSEiIuq+GOCJdFSzlpp1bKkh\nIiLqDhjgiXRYk5aaO2ypISIi6g4Y4In0AFtqiIiIug8GeCI9wZYaIiKi7oEBnkiPNLbU/H5MwM8t\nNRfZUkNERKRPGOCJ9FCEr8PPLTVb2FJDRESkTxjgifRUSy01dyofCl0WERERPScGeCI99uuWmv/3\nXTZbaoiIiHScoAG+rq4OixcvxsCBAxEYGIjx48cjMzNT4/PMmDEDcrkcH3/8cbNtcrm8xT8bNmzo\niFsg0glsqSEiItIfhkJefM6cOUhPT0dSUhI8PDyQlpaGGTNmYO3atQgJCWnXOQ4cOICcnJxW9xk4\ncCBGjx7dZCwoKOiZ6ybSRY0tNcn7LmFX1jVcLKnAzJf9YW/VQ+jSiIiISAOCBfj8/Hzs3LkTc+fO\nxbRp0wAAY8aMQUJCApYsWYJ169a1eY66ujosXLgQ06dPx/Lly5+6X8+ePfHyyy93VOlEOktiaIAp\ncXLI3W3w3X8K8f++y8b0kX4I7m0vdGlERETUToK10OzatQsSiQSJiYnqMWNjY4wbNw4nT57E7du3\n2zzHmjVrUFNTg+nTp7e5b01NDWpra5+rZiJ98euWmuR9F9lSQ0REpCMEC/CFhYXw8vKCmZlZk/HA\nwECoVCoUFha2erxSqcSKFSswe/Zs9OjRegvA5s2bERwcjMDAQIwaNQoZGRnPXT+RrmtsqRka6ord\nWQquUkNERKQjBAvwSqUSDg4OzcalUikAtPkE/tNPP4WXl1ebrTEhISGYPXs2VqxYgfnz56Ourg6z\nZs3Cjh07nr14Ij3R2FLDVWqIiIh0h2A98DU1NZBIJM3GjY2NAaDVdpf8/Hxs3boVa9euhUgkavU6\nGzdubPL1K6+8goSEBCxevBgjR45s8/hfs7Mz12j/jiSVWgh2bWqZvszJCKkFgvs44pM1OfhiSz7G\nRHlj6kg/GBro5kqz+jIv+oRzop04L9qHc6KdtG1eBAvwJiYmqK+vbzbeGNwbg/yvqVQqfPzxx4iL\ni0N4eLjG1zU1NcWECROwdOlSXL58Gd7e3hodf/duNRoaVBpf93lJpRZQKu91+XXp6fRtTiQA3psY\njOR9l7D1YBHOXFTq5Co1+jYv+oBzop04L9qHc6KdhJgXsVjU6kNjwR6vSaXSFttklEolALTYXgMA\nGRkZyM/Px8SJE1FSUqL+AwDV1dUoKSlBTU1Nq9d2dnYGAFRWVj7PLRDpHbbUEBERaT/BAryvry+K\ni4tx//79JuN5eXnq7S0pLS1FQ0MDpk6dimHDhqn/AEBqaiqGDRuGrKysVq+tUCgAALa2ts97G0R6\nqXGVGnurHlylhoiISMsI1kITHx+PVatWISUlRb0OfF1dHVJTUxEaGgpHR0cAjwP7w4cP1a0uQ4cO\nhZubW7Pz/eEPf8CQIUMwbtw4+Pv7AwDKysqahfTy8nKsX78ebm5u8PT07LwbJNJxjjam+J/XwrBp\n3yXszlLgUkmlTrbUEBER6RvBAnxQUBDi4+OxZMkSKJVKuLu7Iy0tDaWlpVi4cKF6v/feew9ZWVm4\ncOECAMDd3R3u7u4tnlMmkyEmJkb99bp167B3715ER0fDxcUFt27dQnJyMsrKyvDVV1917g0S6QGJ\noRiT43wgd7fGdz/wxU9ERETaQLAADwCLFi3CZ599hm3btqGyshJyuRwrV65EWFhYh5w/JCQEubm5\nSElJQWVlJUxNTREcHIyZM2d22DWIuoNwXwe4O5rj661n8cWWfMRFyDAu2ltnV6khIiLSZSKVStX1\nS6roMK5CQ42645zU/9SATfsuYW9uCXq6WOJNLWyp6Y7zou04J9qJ86J9OCfaiavQEJFOa2ypeWtM\nAG7cfbxKzamLSqHLIiIi6lYY4IlIY+G+Dvhw2uNVapZvOYONe7lKDRERUVdhgCeiZ+LwZJWaYaFu\nSM9W4O/rcnGn8qHQZREREek9Bngiema/bqn5aBVbaoiIiDobAzwRPbfGlhqpNVtqiIiIOhsDPBF1\nCLbUEBERdQ0GeCLqMGypISIi6nwM8ETU4dQtNTZsqSEiIupoGgf4q1ev4tChQ03G8vLy8Oabb2LC\nhAlITk7usOKISHc52Jjif6awpYaIiKijGWp6wJIlS1BRUYHBgwcDAMrKyjBjxgw8ePAAxsbG+Oij\nj2BnZ4eYmJgOL5aIdEtjS43c3Rrf/VCIj1ZlY/rIPgjxkQpdGhERkc7S+Al8QUEBXnzxRfXXO3fu\nRHV1NVJTU5GZmYmgoCCsXit2etkAACAASURBVL26Q4skIt3WpKUmlS01REREz0PjAF9WVgYHBwf1\n14cPH0ZoaCh8fHxgZGSEESNGoKioqEOLJCLdp26pCXvcUrPw37m4U8GWGiIiIk1pHOB79OiBe/fu\nAQAePXqEkydPIjw8XL3dxMQE1dXVHVchEekNiaEYk2Mfr1Jzs+w+PvouG6d+5Co1REREmtA4wPfu\n3Rtbt25FeXk5Nm3ahAcPHmDAgAHq7devX4etrW2HFklE+oUtNURERM9O4w+xTp8+HW+99Za6D75P\nnz5NnsAfPXoUfn5+HVchEemlxpaaTfsvIT1bgYsllfj9y/6wt+4hdGlERERaTeMAHx0djdWrV2Pv\n3r0wNzfHlClTIBKJAADl5eVwcnLCmDFjOrxQItI/jS01ctmTVWq+4yo1REREbRGpVCqV0EXokrt3\nq9HQ0PXfMqnUAkrlvS6/Lj0d56Rj3S5/gK+3ncXVm/cQFyHDuGhvGBpo/q45zov24ZxoJ86L9uGc\naCch5kUsFsHOzvzp2zviIj/99BN2796NTZs2QankB9KISHNcpYaIiKh9NG6hWbRoEU6cOIEtW7YA\nAFQqFV5//XXk5ORApVLB2toamzZtgru7e4cXS0T6jS01REREbdP4Cfzhw4ebfGh13759yM7OxvTp\n07F06VIAwMqVKzuuQiLqdsJ9HfDh6y9wlRoiIqIWaPwE/ubNm/Dw8FB/vX//fri5ueGdd94BAFy8\neBHff/99x1VIRN2Sg3UPrlJDRETUAo2fwNfX18PQ8Ofcf+LECfWSkgAgk8nYB09EHaKxpeYPrwTg\nZtkDvviJiIgIzxDgnZyccOrUKQCPn7YrFApERESot9+9exempqYdVyERdXthcgd8+HoEHNhSQ0RE\npHkLzciRI7FixQqUlZXh4sWLMDc3R1RUlHp7YWEhP8BKRB3OwboH5k4JQwpbaoiIqJvT+An8zJkz\n8corr+D06dMQiUT45JNPYGlpCQC4d+8e9u3bh8jIyA4vlIhIYijGpF+11OSypYaIiLqZDn2RU0ND\nA+7fvw8TExNIJJKOOq1W4YucqBHnRFi3Kx7im60FuHLzHmLDZXB3NMfWw5dRVlULW0tjjI3yRqS/\nk9BlEvizoq04L9qHc6KdtPFFThq30LR+MTEsLCw68pRERC36ZUtNRo4CIgCNv1rfrarF6h/OAwBD\nPBER6Z1nehPrgwcP8MUXX2DUqFEICQlBSEgIRo0aheXLl+PBgwcdXSMRUYsaW2rMe0jw6/8vVvdT\nA1IPFglSFxERUWfS+Al8RUUFJk+ejKKiItja2qJPnz4AgCtXruCrr77Crl27sG7dOlhbW3d4sURE\nLal+WN/i+N2q2i6uhIiIqPNp/AT+iy++wOXLl/HBBx/g8OHDWL9+PdavX4/Dhw9j/vz5KC4uxpdf\nftkZtRIRtcjO0vip2/5v+1kU36jqwmqIiIg6l8YBft++fUhMTMTkyZNhYGCgHjcwMMCkSZPw6quv\nYs+ePR1aJBFRa8ZGecPIsOlfZxJDMQK8bJFfdAd/XZ2D//33SeScvy3Ih9CJiIg6ksYtNHfu3FG3\nzbTEz88PaWlpz1UUEZEmGj+omnqwqNkqNA9rf8KR/BvIyFFgxdYC2FuZYFiYGwYFusDUpEM/x09E\nRNQlNP7Xy97eHoWFhU/dXlhYCHt7+3adq66uDp9//jm2bduGqqoq+Pr6Yvbs2RqvIz9jxgwcOnQI\nSUlJmDdvXrPtKSkpWLVqFUpKSuDi4oKkpCRMnjxZo2sQkXaL9HdCpL9Ts+W+ehgbIjZChmFhbjh1\n8Q4ychRI3ncJ244UY2CgM2LCZXDgy6CIiEiHaNxCM2TIEGzevBkbN25EQ8PPrzJvaGhAcnIytmzZ\ngqFDh7brXHPmzMHq1asxevRozJs3D2KxGDNmzMCpU6faXc+BAweQk5Pz1O0bN27E+++/Dx8fH3zw\nwQcICgrCggULsGrVqnZfg4h0n1gsQphcijmTQzF/WjhCettjf+51zP0mE1+mnsGPigp04GsxiIiI\nOo3GL3IqLy/HhAkTcO3aNdja2sLLywsAUFxcjLKyMri7u2Pjxo2wsbFp9Tz5+flITEzE3LlzMW3a\nNABAbW0tEhIS4ODggHXr1rVZS11dHUaNGqVewvLXT+BramoQFRWFsLAwrFixQj3+zjvvYN++fTh4\n8KDG69bzRU7UiHOinTSZl/J7tdiXW4IDp67jfs1P8HCyQFy4DBF9HGBo8Eyr7FIL+LOinTgv2odz\nop208UVOGv8LZWNjgy1btuCNN96AtbU1zpw5gzNnzsDGxgZvvPEGtmzZ0mZ4B4Bdu3ZBIpEgMTFR\nPWZsbIxx48bh5MmTuH37dpvnWLNmDWpqajB9+vQWt584cQIVFRWYNGlSk/HJkyfj/v37OHToUJvX\nICL9ZWNhjFejvLHkDwOQ9JIcdfWP8O2Oc3j362PYcezKU5enJCIiEtIzfYLL3Nwcs2fPxuzZs5tt\n27hxI9asWYP//Oc/rZ6jsLAQXl5eMDMzazIeGBgIlUqFwsJCODg4PPV4pVKJFStWYP78+ejRo+X+\n1XPnzgEAAgICmoz7+/tDLBbj3LlzGDlyZKt1EpH+M5YYIDrEFYODXXC2uAzp2QqkHrqMHceu4MUA\nJ8SEy+Bib9b2iYiIiLpAhy/BUF5ejuLi4jb3UyqVcHR0bDYulUoBoM0n8J9++im8vLzw8ssvt3oN\nIyOjZi+Vahxrz1N+Iuo+xCIR+va0Q9+edriurEZGjgJHztzEgdOlCOhpi7gIGfw9bSESiYQulYiI\nujHB1lCrqamBRCJpNm5s/PiFLLW1T3+DYn5+PrZu3Yq1a9e2+g/p067ReJ3WrvE0rfUjdTapVLN+\nfep8nBPt1BHzIpVaINjPGZXVtdiVeQU7jxbj0+Q8uDtZYPQgb0SHucFYYtDmeegx/qxoJ86L9uGc\naCdtmxfBAryJiQnq65v3lzaG6sYg/2sqlQoff/wx4uLiEB4e3uY16urqWtxWW1v71Gu0hh9ipUac\nE+3UGfMyNNgFgwKckFV4CxnZCnyZchr/2nEW0SGuGBbqCitzzf8u6U74s6KdOC/ah3OinbTxQ6yC\nBXipVNpiC4tSqQSAp/a/Z2RkID8/H7Nnz0ZJSUmTbdXV1SgpKYG9vT1MTEwglUpRX1+PioqKJm00\ndXV1qKioaLXHnojolySGYgzo64wXA5xw4VoF0rMV2HnsCn44fhX9/BwRFyGDu6N2PaEhIiL9JFiA\n9/X1xdq1a3H//v0mH2TNy8tTb29JaWkpGhoaMHXq1GbbUlNTkZqaim+//RaDBw9WvzG2oKAAAwcO\nVO9XUFCAhoaGVt8oS0TUEpFIBF8PG/h62OBW+QPsySnBkfwbOFZwE77u1oiNkCHI2x5iMfvkiYio\nc7QrwH/33XftPmFubm679ouPj8eqVauQkpKiXge+rq4OqampCA0NVX/AtbS0FA8fPoS3tzcAYOjQ\noXBzc2t2vj/84Q8YMmQIxo0bB39/fwBA//79YW1tjfXr1zcJ8Bs2bICpqSkGDx7c7vsiIvo1RxtT\nTI71wSuDvHAo7wb2nlRg+ZYzcLDugZhwNwwMdIaJkWDPSYiISE+161+WTz75RKOTtmeFhqCgIMTH\nx2PJkiVQKpVwd3dHWloaSktLsXDhQvV+7733HrKysnDhwgUAgLu7O9zd3Vs8p0wmQ0xMjPprExMT\nvP3221iwYAH+9Kc/YeDAgcjJycH27dvxzjvvwNLSUqP7IiJqiamJBPH93BEb4YbcH+8gPfsa1u+5\niLTDxYgKcsGwMDfYWZkIXSYREemJdgX4NWvWdMrFFy1ahM8++wzbtm1DZWUl5HI5Vq5cibCwsA67\nxuTJkyGRSLBq1Srs3bsXzs7OmDdvHpKSkjrsGkREAGAgFiPC1wERvg4oKq1ERrYC6U/+hMqliIuQ\noZerldBlEhGRjhOpVKquX1JFh3EVGmrEOdFO2jYvdytrsDe3BAdPl+Jh7U/o6WKJuAgZwuRSGIg1\nfhm2TtK2OaHHOC/ah3OinbgKDRFRN2NnZYLxQ3ph9ABPHD1zExk5Cnyz7SxsLY0xLMwNUUEuMDVp\n+X0VRERELWGAJyLqAiZGhhgW5oYhoa7Iv3QX6dnXkLK/CNuPXMGAvk6IDZfB0dZU6DKJiEgHMMAT\nEXUhsUiE4N72CO5tj2u37iEjR4FDeaXYn3sdQb3sERshg6+7dbsWAyAiou6JAZ6ISCDujhaYPtIP\n46K8sf/Udew/dR2nN9yBzMEcseEy9PNzhMSwe/TJExFR+zHAExEJzMrcGGMG9cTISA9knr2FjGwF\nVv2nEJsPFmFoiCuiQ1xhaWYkdJlERKQlGOCJiLSExNAAg4NcMCjQGeeulCMjR4GtR4qxI/MqIv0d\nERshg5v06asSEBFR98AAT0SkZUQiEfy9bOHvZYsbd+8jI6cEx87cwOH8G/D3tEFshAwBPe0gZp88\nEVG3xABPRKTFnO3MkPSSHGMH98TB09ex92QJPkvJh7OdKWLCZXgxwAnGEgOhyyQioi7EAE9EpAPM\ne0gwMtITL73gjpzzt5GercDa3ReQerAI0SGuGBrqBhsLY6HLJCKiLsAAT0SkQwwNxOjv74R+fo64\nWFKJjGwF/nP8KnaduIYIXwfERsjg5WwpdJlERNSJGOCJiHSQSCSCj8waPjJrKCseYk9OCQ7nl+L4\nuVvo7WaFuAgZQnpLIRazT56ISN8wwBMR6TipdQ9MjOmNMYO8cDj/BvbkKPBVWgHsrUwQE+aGQUEu\n6GHMv+6JiPQF/0YnItITPYwNERchQ0yYG05dVCI9W4GN+y5h65FiDAp0QUy4G6TWPYQuk4iInhMD\nPBGRnhGLRQiTOyBM7oDiG1XIyFFgX24J9pxUILS3FLERMvR2s4KIy1ASEekkBngiIj3m5WyJN0b5\nIzG6F/blluDAqes4+aMSnk4WiI2QIcLXAYYGYqHLJCIiDTDAExF1AzYWxng1yhsJL3riWMFNZGQr\n8O3355Cy/xKGhbkhKtgV5j0kQpdJRETtwABPRNSNGEsMMCTEFVHBLii4XIaM7GvYcvAyvj96BS8G\nOCE2QgZnOzOhyyQiolYwwBMRdUNikQiB3nYI9LZDibIaGdkKHDlzEwdOl6JvTzvERcjg52nDPnki\nIi3EAE9E1M25Sc3x+og+eDXKGwdOX8e+3OtYmnwarlIzxIbLEOnvCImhgdBlEhHREwzwREQEALA0\nM8LoAV4Y3s8DWYW3kJ6twL9+OI8tB4sQHeyKoaGusDI3FrpMIqJujwGeiIiakBiKMaCvM14McML5\naxXIyFZgx7Er+OHEVfTr44jYCBncHS2ELpOIqNtigCciohaJRCL08bBBHw8b3Cp7gD05JThy5gaO\nFtyEr7s1YiNkCOplDzH75ImIuhQDPBERtcnR1hST43wwZrAXDuWVYu/JEizfcgYONj0QGy7DgL5O\nMDHiPylERF2Bf9sSEVG7mZlIMLyfB2LDZcj9UYn0bAXWZfyItEOXMTjYBTFhbrC1NBG6TCIivcYA\nT0REGjM0EOOFPo54oY8jiq5XIj1bgfSsx3/CfaWIDZfB29VK6DKJiPQSAzwRET0Xb1cr/N7VCncr\na7D3ZAkO5pUiq/A2vF0sERshQ7wtXwxFRNSRGOCJiKhD2FmZYPzQXhg90BNH8m9gT04Jvtl2FlsO\nXcaQYFcMDnKGqYlE6DKJiHQeAzwREXUoEyNDxITLMDTUDXlFd3Dg9A1s2n8J244UY2BfZ8REuMHR\nxlToMomIdBYDPBERdQqxWISQ3lLEvdgTOWdKkZGjePKm1xIE9bJHXIQMcndriLgMJRGRRhjgiYio\n03k4WeB3CX4YF+2N/bnXsf/UdZy+dAfuDuaIjZDhhT6OkBiKhS6TiEgnMMATEVGXsTY3xiuDe2Jk\npAeOn7uFjGwF/rmzEJsPFGFIqCuiQ1xhaWokdJlERFqNAZ6IiLqckcQAg4NcMCjQGWevlCEjuwRb\nDxdjZ+ZVRPo7IjZcBlepudBlEhFpJUEDfF1dHT7//HNs27YNVVVV8PX1xezZsxEZGdnqcdu3b8fm\nzZtRVFSEyspKODg4oF+/fpg1axZcXV2b7CuXy1s8x0cffYSJEyd22L0QEZHmRCIRArzsEOBlh9I7\n97EnR4FjBTdxKO8G/D1tEBvhjoCethCzT56ISE3QAD9nzhykp6cjKSkJHh4eSEtLw4wZM7B27VqE\nhIQ89bjz58/D0dERUVFRsLKyQmlpKTZt2oQDBw5g+/btkEqlTfYfOHAgRo8e3WQsKCioU+6JiIie\njYu9GZLifTE2yhsHTl3H3twSfJaSB2c7U8SGyxAZ4ARjiYHQZRIRCU6kUqlUQlw4Pz8fiYmJmDt3\nLqZNmwYAqK2tRUJCAhwcHLBu3TqNznf27FmMHTsW7777LqZPn64el8vlSEpKwrx58zqk7rt3q9HQ\n0PXfMqnUAkrlvS6/Lj0d50Q7cV60z7POyU+PGpBdeBvp2QpcvXUPZiaGiA5xxdBQN9hYGHdCpd0L\nf1a0D+dEOwkxL2KxCHZ2T28jFOwJ/K5duyCRSJCYmKgeMzY2xrhx47Bs2TLcvn0bDg4O7T6fi4sL\nAKCqqqrF7TU1NRCJRDA25l/6RES6wNBAjMgAJ/T3d8TFkkqkZyvwn8yr2HXiGiL6OCAuQgZPJ0uh\nyyQi6nKCBfjCwkJ4eXnBzKzpK7YDAwOhUqlQWFjYZoCvqKjAo0ePUFpaiq+++goAWuyf37x5M9au\nXQuVSgUfHx+8/fbbiI2N7bibISKiTiMSieAjs4aPzBq3Kx5iT44Ch/Nv4PjZW/Bxs0JshDtCettD\nLGafPBF1D4IFeKVSCUdHx2bjjf3rt2/fbvMcL730EioqKgAA1tbWmD9/Pvr3799kn5CQEIwYMQJu\nbm64ceMG1qxZg1mzZmHp0qVISEjogDshIqKu4mDdA5NifDBmYE8cyS/FnpMl+CrtDKTWJogJk2Fg\noDN6GHOBNSLSb4L9LVdTUwOJRNJsvLHFpba2ts1zfPnll3jw4AGKi4uxfft23L9/v9k+GzdubPL1\nK6+8goSEBCxevBgjR47U+A2ArfUjdTap1EKwa1PLOCfaifOifTpjTjxkNpgQ3wfHz97EtoNF2LD3\nIrYdLUbsCx4YNagnHG1NO/ya+oY/K9qHc6KdtG1eBAvwJiYmqK+vbzbeGNzb06seEREBAIiKisKw\nYcMwatQomJqaYsqUKU89xtTUFBMmTMDSpUtx+fJleHt7a1Q3P8RKjTgn2onzon06e058nC3wlwnB\nKL5RhfRsBXYcuYzth4sQ6iNFbLgMvd2sNH5Y0x3wZ0X7cE60kzZ+iFWw91ZLpdIW22SUSiUAaPQB\nVgCQyWTw9/fH999/3+a+zs7OAIDKykqNrkFERNrLy9kSM0f745M3IzG8nwfOXy3H39fl4q+rc3D8\n7E389KhB6BKJiDqEYAHe19cXxcXFzdpe8vLy1Ns1VVNTg3v32v4NSaFQAABsbW01vgYREWk3W0sT\njIv2xpK3BuC1OB88rHuEld+fw3vfZGJn5hVUP2z+f3+JiHSJYAE+Pj4e9fX1SElJUY/V1dUhNTUV\noaGh6g+4lpaWoqioqMmxZWVlzc5XUFCA8+fPw9/fv9X9ysvLsX79eri5ucHT07OD7oaIiLSNsZEB\nhoS64eMZ/fDnxEA425liy8HLeGfFUazdfQE37jb/3BQRkS4QrAc+KCgI8fHxWLJkCZRKJdzd3ZGW\nlobS0lIsXLhQvd97772HrKwsXLhwQT02ZMgQDB8+HD4+PjA1NcWlS5ewZcsWmJmZ4a233lLvt27d\nOuzduxfR0dFwcXHBrVu3kJycjLKyMvWyk0REpN/EIhECve0R6G2PktvVSH+yDOX+U9cR6G2H2AgZ\n/Dxs2CdPRDpD0LW2Fi1ahM8++wzbtm1DZWUl5HI5Vq5cibCwsFaPmzRpEjIzM7Fnzx7U1NRAKpUi\nPj4eb731FmQymXq/kJAQ5ObmIiUlBZWVlTA1NUVwcDBmzpzZ5jWIiEj/uDmY47cj+mBclDf2n7qO\n/bklWLrxNNykZogNl6G/vyMkhgZCl0lE1CqRSqXq+iVVdBhXoaFGnBPtxHnRPto8J/U/PcKJc7eR\nnq1AibIaFqYSDAlxxZBQN1iZGQldXqfS5nnprjgn2kkbV6Hh2y6IiKjbkhgaYGCgMwb0dcL5q+VI\nz1Zg+9Er+M/xq+jn54jYcBncHbVr/WciIgZ4IiLq9kQiEfp42qKPpy1ulj3AnhwFjpy5gaNnbqKP\nhw1iI2QI9LaDmH3yRKQFGOCJiIh+wcnWFFPi5HhlcE8cOl2KPSdL8MXmfDja9EBMuAwD+zrD2Ih9\n8kQkHAZ4IiKiFpiZSDC8vwdiI2Q4eUGJ9GwF1mX8iLRDlxEV7IJhYW6wtTQRukwi6oYY4ImIiFph\naCBGPz9HvNDHAUXXq5Ceo8CurGvYnaVAuK8UsREyeLtYCV0mEXUjDPBERETtIBKJ0MvNCr3crHCn\n8iH2nizBobxSZBXehrerJeIi3BHqYw8DsWDvSCSiboIBnoiISEP2Vj3wm6G9MXqAF46cuYE9OQp8\nvbUAdpYmGBbmhsFBzjA1kQhdJhHpKQZ4IiKiZ9TD2BCx4TIMC3VD3qU7SM9WYNP+S9h2tBgD+zoj\nNtwNDjamQpdJRHqGAZ6IiOg5icUihPhIEeIjxdWb95CercCBU9ex72QJgnvbIy5CBh+ZNURchpKI\nOgADPBERUQfycLLAjFF+GBftjf2nSnDgVClOXbwDd0dzxEXI8EIfRxgasE+eiJ4dAzwREVEnsLEw\nxtjB3kiI9ETm2ZvIyCnBP3YUImV/EYaGuiI6xBUWpkZCl0lEOogBnoiIqBMZSQwQFeyKwUEuOFtc\nhvRsBdIOF2NH5lVE+jshNkIGV3szocskIh3CAE9ERNQFRCIRAnraIaCnHa7fuY89OQocK7iJQ3ml\n8PeyRVyEDAFetuyTJ6I2McATERF1MVd7M0yN98XYwT1x4HQp9uWWYNmmPDjbmSI2QoYX/Z1gJDEQ\nukwi0lIM8ERERAKxMDXCqBc9MbyfO7IKbyE9W4E1uy4g9eBlRIe4YGioG6zNjYUuk4i0DAM8ERGR\nwAwNxHgxwBmR/k74UVGB9GwFdh67ih+OX8MLfRwQF+EODycLocskIi3BAE9ERKQlRCIR5O42kLvb\n4Hb5A+zJKcHhMzeQefYWfGTWiIuQIbiXPcRi9skTdWcM8ERERFrIwcYUk2J9MGZQTxzOL8WenBJ8\nmXoGUmsTxITJMDDQGT2M+c84UXfEn3wiIiItZmpiiJdecEdMuBtO/XgH6dkKbNh7EVuPXMagQBfE\nhLnB3rqH0GUSURdigCciItIBBmIxwn0dEO7rgMulVcjIUWBPTgkychQI85EiLsId3q6WXIaSqBtg\ngCciItIxPV0sMXO0PxKjvbE3twQHT5Ui54ISXs6WiI1wQ7jcAYYGYqHLJKJOwgBPRESko2wtTZAY\n3QujX/TC0YIbyMhWYOX2c0ixKMKwMDdEBbvAzEQidJlE1MEY4ImIiHScsZEBhoa6ITrEFflFd5GR\nrcDmA0XYfrQYA/o6IzZcBidbU6HLJKIOwgBPRESkJ8QiEYJ72SO4lz0Ut6uRka3A4bxS7M+9jkBv\nO8RFyFBRXYu0Q5dRVlULW0tjjI3yRqS/k9ClE5EGGOCJiIj0kMzBHL8d2QevRntjf24J9p+6jiUb\nT0MEQPVkn7tVtVj9w3kAYIgn0iH8hAsREZEeszIzwphBPbHkrRdhZmKoDu+N6n5qQPK+S3jU0CBI\nfUSkOT6BJyIi6gYkhga4X/NTi9uq7tfh7c+PoI+HDfy9bOHvaQMHG/bME2krBngiIqJuws7SGHer\napuNm/eQIKS3Pc5dKUPuj0oAgL2VCQK8bOHnaYs+njZczYZIizDAExERdRNjo7yx+ofzqPvp53YZ\nI0MxJsb0RqS/E1QqFW6WPcC5K+U4W1yGzHO3cOB0KUQiwMvZEn6ej5/Oe7tacZ15IgExwBMREXUT\njR9UTT1Y1OIqNCKRCM52ZnC2M8OwMDf89KgBl0urcO5KGc5eKcPOzCvYcewKjI0M4Cuzhp+XLQK8\nbOFka8o3wBJ1IQZ4IiKibiTS3wmR/k6QSi2gVN5rdV9DAzF8ZNbwkVljzKCeeFBTj8KrFY8DfXEZ\n8oruAgBsLIzh72kLf6/H7TaWpkZdcStE3RYDPBEREbWLqYkEYXIpwuRSAICy4iHOPgnzuT8qceTM\nDQCAu6P5kw/D2qK3mxUkhgZClk2kdwQN8HV1dfj888+xbds2VFVVwdfXF7Nnz0ZkZGSrx23fvh2b\nN29GUVERKisr4eDggH79+mHWrFlwdXVttn9KSgpWrVqFkpISuLi4ICkpCZMnT+6s2yIiIuoWpNY9\nEB3siuhgVzQ0qHDl5j2cLb6Ls1fKkZ6lwA/Hr8HI8PFTfL8nT+jdpGZstyF6ToIG+Dlz5iA9PR1J\nSUnw8PBAWloaZsyYgbVr1yIkJOSpx50/fx6Ojo6IioqClZUVSktLsWnTJhw4cADbt2+HVCpV77tx\n40Z8+OGHiI+Px+uvv46cnBwsWLAAtbW1+O1vf9sVt0lERKT3xGIRerpYoqeLJUYN8MLD2p9wQVGB\nc8WP++c37b8E7AcszYzg72mjDvTW5sZCl06kc0QqlerX73ToEvn5+UhMTMTcuXMxbdo0AEBtbS0S\nEhLg4OCAdevWaXS+s2fPYuzYsXj33Xcxffp0AEBNTQ2ioqIQFhaGFStWqPd95513sG/fPhw8eBAW\nFhYaXefu3Wo0NHT9t6w9vYrUtTgn2onzon04J9qpq+elrKoGZ6+UqVe4qX5YDwBwlZrB3/PxcpVy\nmTWMjbpvuw1/VrSTEPMiFotgZ2f+1O2CPYHftWsXJBIJEhMT1WPGxsYYN24cli1bhtu3b8PBwaHd\n53NxcQEAVFVVqcdOSS49tAAAIABJREFUnDiBiooKTJo0qcm+kydPxvfff49Dhw5h5MiRz3knRERE\n1BZbSxMMCnTBoEAXNKhUUNyqxrkrZSgoLsO+3OtIz1bA0ECEXq5Wj/vnvWzh7mgBMdttiJoRLMAX\nFhbCy8sLZmZmTcYDAwOhUqlQWFjYZoCvqKjAo0eP/n97dx4dVXn/cfw9k0xWssyQhZCdYCYhSAJR\nWasg/DQiFNG6I7UW1FpPleopou2vLT3VHmtV3I4baKFaa5CIYCtY5Kc1BS0gwRAIEBIBAyESkkBC\nMiEzvz+GzOmQhC3LzCSf11/kmfvMPDffXO4nN899LpWVlbz44osAbvPnS0pKABg+fLhbv6ysLIxG\nIyUlJQrwIiIivcxoMJA8KIzkQWFcMyaZ5pZWdh+opaT8KMXlNbz36V7e+3QvA4JN//V0WAsDI4I8\nPXQRr+CxAF9dXU1sbGy79rb564cPHz7re1x99dXU1tYCEBkZyf/+7/8yZswYt88ICAggMjLSrV9b\n27l8hoiIiPSsQJMfw1MHMjx1IDcBdQ0211KV2ytq+M9O5/k61hJCVooz0GckmQkO1GJ60j957Ce/\nqakJk6n9Y5kDA503szQ3t3/U8+leeOEFGhsbKS8v54MPPqChoeGcPqPtc87lM053pvlIPS06+vzm\n60vPU028k+rifVQT7+StdYmOhqEpA/n+RHA4HOyrOsZXpdVs3XWYwuJDfLLlW4xGA9YkMyOtMYxM\nj+aixEj8+sDTYb21Jv2dt9XFYwE+KCiIlpaWdu1tobotyJ/JpZdeCsAVV1zB5MmTmT59OiEhIcya\nNcv1GTabrcO+zc3N5/QZp9NNrNJGNfFOqov3UU28ky/VJcTPwPhhMYwfFkPLSTt7vq1zXaH/65qd\nvL1mJ8GB/s7pNilmhqVaiIkM9rnlKn2pJv2JbmL9L9HR0R1OYamurgY4rxtYARITE8nKymLVqlWu\nAB8dHU1LSwu1tbVu02hsNhu1tbXn/RkiIiLiWSZ/I5nJZjKTzdxwRRrHT7RQUlHjCvRbdjlzRFRE\nkGvufEaymQHBHf9FXsQXeSzAZ2RksGzZMhoaGtxuZC0qKnK9fr6ampo4ceKE6+vMzEwAiouLmTBh\ngqu9uLgYu93uel1ERER804BgE5dlxnJZZiwOh4OqoyfYXu4M9F+UVPHp1koMBkgZFE5WqpmsFAtp\n8RH494HpNtJ/eSzA5+XlsWTJEvLz813rwNtsNlasWMGoUaNcN7hWVlZy4sQJ0tLSXH1ramqwWCxu\n71dcXMzOnTuZOnWqq23MmDFERkby9ttvuwX4v/71r4SEhHD55Zf34B6KiIhIbzIYDAyyhDDIEsLk\n3AROttopP1jvuhn27xv2sfrf3xBo8sOaFOm6Qh83MMTnpttI/+axAJ+dnU1eXh5PPfUU1dXVJCUl\nUVBQQGVlJU888YRru/nz5/Pll19SWlrqaps0aRLXXHMN6enphISEsGfPHt577z1CQ0O57777XNsF\nBQXxs5/9jIULF/LAAw8wYcIENm3axAcffMDDDz9MeHh4r+6ziIiI9B5/PyMXJURyUUIk131vCI1N\nJ9m576gr0G8rOwKAOSzQ+TCpVOcTYsNDAjw8cpEz8+j6S08++STPPvssK1eupK6uDqvVyquvvkpu\nbu4Z+912221s2LCBf/7znzQ1NREdHU1eXh733XcfiYmJbtvefvvtmEwmlixZwrp164iLi+Oxxx5j\n9uzZPblrIiIi4mVCgvwZlR7NqHTnktXVtSecT4ctr+Gr3dV8/vVBAJJiBpCVamFYqoX0hAhM/v33\n6bDinQwOh6P3l1TxYVqFRtqoJt5JdfE+qol3Ul3c2e0Ovqk6RnG5M9Dv+baOVrsDk7+R9MRI5xX6\nFDOJMQN6bLqNauKdtAqNiIiIiBcyGg2kxoWTGhfO9HEpNNlOUrqvlu2nVrd5d/0eAMJDAxiWYj4V\n6C2Yw85/SWqRrlKAFxERETlNUIA/2UOjyB4aBUBNfRMlFUddy1Vu3F4FQHxUKMNSLGSlWrAmRhIY\noOk20vMU4EVERETOwhIexIQRcUwYEYfd4eDA4eOuq/Prv/qWjzftx9/PwND4CFegT44Nw2jU6jbS\n/RTgRURERM6D0WAgKTaMpNgwrhmdjK2lld0H6lyr26z4bC8rPttLaJA/mSkWhqc6589HRQR7eujS\nRyjAi4iIiHRBgMnPuaZ8qvMZNXUNNufTYU8F+k07nU+ejzUHuz0dNjhQMUwujH5yRERERLpRRGgA\nY7MGMTZrEA6Hg8rvGth+av78518f5JMt32I0GBgSH05WijPQpw4O8/SwxYcowIuIiIj0EIPBQHz0\nAOKjB3DVpYm0nLRT9m2dc/35iho++LyclZ+XExzoR/ZF0Qwd7Az1MeZgPR1WOqUALyIiItJLTP5G\nMpLNZCSbueGKNI6faGHHN86nw+7cd5SNxYcAiIoIct0Mm5lsZkCwycMjF2+iAC8iIiLiIQOCTVya\nEcOlGTFERQ1g+67DrtVt/rOzis+KKjEAKXFhrvnzafER+PsZPT108SAFeBEREREvYDAYiLWEEGsJ\n4cpRCbTa7ZRXHqO4/AglFUf5+4Z9rP73NwSa/LAmnXo6bKqFwQNDNN2mn1GAFxEREfFCfkYjQxMi\nGJoQwXXfg8amk5TuO0rxqRVutpUdAcAcFuj2dNjw0AAPj1x6mgK8iIiIiA8ICfJnZHo0I9OjAfiu\n9oRzuk3FUbbu/o7Cr53z55NiBjDs1HSbixIiCDDp6bB9jQK8iIiIiA+Kigzmipx4rsiJx2538E3V\nMbaXO1e3+fg/+/noi32Y/I2kJ0S4An1CzACMmm7j8xTgRURERHyc0WggNS6c1Lhwpo1Locl2kl37\na9lefpTtFTXkry8jnzLCQ0wMOzXVJivVgjks0NNDlwugAC8iIiLSxwQF+DMiLYoRaVEAHD3WTMmp\n1W1KKmrYWFIFwOCoUIalmBmeasGaaCYwQNNtfIECvIiIiEgfZw4LZPzFcYy/OA67w8GBw8edD5Mq\nr+HTrZX8c9MB/IwGhsZHOJerTLWQHBuG0ajpNt5IAV5ERESkHzEaDCTFhpEUG8Y1o5OxtbSy+0Cd\nK9Cv+GwvKz7bS2iQP5kpFrJOrXATFRns6aHLKQrwIiIiIv1YgMnPddWdSVDfYHNOt6mooaTiKJt2\nHgYg1hzsuhk2I8lMSJBipKfoOy8iIiIiLuGhAYzJGsSYrEE4HA4qjzRSUu4M9P/++hDrt3yL0WBg\nyOBw5/rzqRaGDA7Hz6inw/YWBXgRERER6ZDBYCA+KpT4qFD+59JETrbaKfvWOd1me3kNqwor+KCw\nguBAPzKSnGE+K8VCjDlYT4ftQQrwIiIiInJO/P2MWJPMWJPMXH95GsdPtLDzm6MUn1rd5qvd3wEw\nMDyIrFQzWakDyUw2MyDY5OGR9y0K8CIiIiJyQQYEm7gkI4ZLMmJwOBwcrj1BSXkNxeU1/GfnYT4r\nOogBSB4U5ro6PzQhAn8/TbfpCgV4EREREekyg8FArDmEWHMIk0Yl0Gq3U155zDndpqKGf2zcx4cb\nviHAZCQjyex8mFSKmcFRoZpuc54U4EVERESk2/kZjQxNiGBoQgQzJqTS2HSS0n1HTwX6o2wr2w1A\n5IAAslIsDEt1PiE2IjTAwyP3fgrwIiIiItLjQoL8GZkezcj0aAC+qztBScVRtpfXsHXPdxQWHwIg\nMWbAqUBvJj0hkgCTng57OgV4EREREel1URHBXJ4dzOXZg7HbHXxTdcy5/nx5DR9v2s9HX+7D389I\nemIEWSnOdeoTYgZg1HQbBXgRERER8Syj0UBqXDipceFcOzaFZlsrpftr2X5qdZv8/ysj///KCAsx\nnZo77wz05rBATw/dIxTgRURERMSrBAb4MSJtICPSBgJw9Fiz29NhvyipAiBuYIhrdRtrUiRBAf0j\n2vaPvRQRERERn2UOC2T8xXGMvzgOh8PBgeoGtp96OuynWyv556YD+BkNDI2PYNipQJ8yKAyjsW9O\nt1GAFxERERGfYTAYSIwZQGLMAPJGJ9FyspVdB+ooORXoCz7bS8FnewkN8icz2ewK9NGRwZ4eerdR\ngBcRERERn2Xy93POiU+xcCNQ32Cj5JsaSsqdS1ZuKq0GIMYc7Jo7n5FkJiTId2Ow745cREREROQ0\n4aEBjBk2iDHDBuFwODh4pNG59nx5Df8uPsT6r77FaDCQOjjMFehT48LbPR12w/ZDrPi0jJr6Zizh\ngVx/RRpjswZ5aK/ceTTA22w2Fi1axMqVK6mvrycjI4N58+YxduzYM/Zbu3Ytf//739m2bRtHjhwh\nLi6OSZMmcd999xEWFua2rdVq7fA9fvOb33Drrbd2276IiIiIiHcxGAwMjgplcFQo/3NJIidb7ZR9\nW8f2U+vPr/p3BR8UVhAU4EdGktl5Q2yqhb2VdSz9qBTbSTsAR+qb+fM/dgJ4RYj3aIB/5JFHWLt2\nLbNnzyY5OZmCggLmzp3LsmXLGDlyZKf9fvWrXxETE8OMGTMYPHgwpaWlLFu2jH/961+89957BAa6\nLyk0YcIEvv/977u1ZWdn98g+iYiIiIh38vczYk0yY00yc/3lQ2hoamFHxVHXFfqte74DwGgAu8O9\nr+2knRWflvXvAL9t2zY+/PBDFixYwJ133gnAddddx7Rp03jqqad46623Ou373HPPMXr0aLe24cOH\nM3/+fD788EOuv/56t9eGDBnCjBkzun0fRERERMR3hQaZuCQjhksyYgA4fLSR7eU1LFu7q8Ptj9Q3\n9+bwOmU8+yY946OPPsJkMnHjjTe62gIDA/nBD37A5s2bOXz4cKd9Tw/vAFOmTAGgrKyswz5NTU00\nN3vHN11EREREvE+MOYRJoxIYGN7xA6I6a+9tHgvwO3bsIDU1ldDQULf2ESNG4HA42LFjx3m933ff\nOf/kYTab2722fPlycnJyGDFiBNOnT+fjjz++8IGLiIiISJ92/RVpBPi7x+QAfyPXX5HmoRG589gU\nmurqamJjY9u1R0dHA5zxCnxHXnvtNfz8/Ljqqqvc2keOHMnUqVNJSEjg4MGDLF26lPvvv58//elP\nTJs27cJ3QERERET6pLZ57lqF5jRNTU2YTKZ27W03oJ7PdJdVq1axfPly7rnnHpKSktxee+edd9y+\nnjlzJtOmTeOPf/wj1157LQbD+T2ha+DAAee1fXeKjg47+0bSq1QT76S6eB/VxDupLt5HNfEe358Y\nxvcnXuTpYXTIYwE+KCiIlpaWdu1twf30lWQ6s2nTJh577DEmTpzIAw88cNbtQ0JCuOWWW/jTn/7E\n3r17SUs7vz+FHDlyHPvptyX3gujoMKqrj/X650rnVBPvpLp4H9XEO6ku3kc18U6eqIvRaDjjRWOP\nzYGPjo7ucJpMdfWpp2XFxJz1PXbu3MlPfvITrFYrzzzzDH5+fuf02XFxcQDU1dWdx4hFRERERDzP\nYwE+IyOD8vJyGhoa3NqLiopcr5/Jvn37mDNnDhaLhVdeeYWQkJBz/uz9+/cDYLFYznPUIiIiIiKe\n5bEAn5eXR0tLC/n5+a42m83GihUrGDVqlOsG18rKynZLQ1ZXV3PXXXdhMBhYvHhxp0G8pqamXdvR\no0d5++23SUhIICUlpft2SERERESkF3hsDnx2djZ5eXk89dRTVFdXk5SUREFBAZWVlTzxxBOu7ebP\nn8+XX35JaWmpq23OnDns37+fOXPmsHnzZjZv3ux6LSkpyfUU17feeot169YxceJEBg8eTFVVFX/7\n29+oqanhxRdf7L2dFRERERHpJh4L8ABPPvkkzz77LCtXrqSurg6r1cqrr75Kbm7uGfvt3LkTgNdf\nf73dazNnznQF+JEjR7Jlyxby8/Opq6sjJCSEnJwc7rnnnrN+hoiIiIiINzI4HI7eX1LFh2kVGmmj\nmngn1cX7qCbeSXXxPqqJd9IqNCIiIiIi0iUK8CIiIiIiPsSjc+B9kdF4fk9u7SufLR1TTbyT6uJ9\nVBPvpLp4H9XEO/V2Xc72eZoDLyIiIiLiQzSFRkRERETEhyjAi4iIiIj4EAV4EREREREfogAvIiIi\nIuJDFOBFRERERHyIAryIiIiIiA9RgBcRERER8SEK8CIiIiIiPkQBXkRERETEhyjAi4iIiIj4EH9P\nD6A/s9lsLFq0iJUrV1JfX09GRgbz5s1j7NixZ+1bVVXF448/TmFhIXa7nTFjxrBgwQISExN7YeR9\n14XW5Pnnn+eFF15o1x4VFUVhYWFPDbdfOHz4MEuXLqWoqIji4mIaGxtZunQpo0ePPqf+ZWVlPP74\n42zZsgWTycSkSZOYP38+Foulh0fet3WlLo888ggFBQXt2rOzs3n33Xd7Yrj9wrZt2ygoKOCLL76g\nsrKSyMhIRo4cyYMPPkhycvJZ++u80v26UhOdV3rO119/zcsvv0xJSQlHjhwhLCyMjIwMfvrTnzJq\n1Kiz9veGY0UB3oMeeeQR1q5dy+zZs0lOTqagoIC5c+eybNkyRo4c2Wm/hoYGZs+eTUNDA/feey/+\n/v68+eabzJ49m/fff5+IiIhe3Iu+5UJr0mbhwoUEBQW5vv7vf8uFKS8v57XXXiM5ORmr1cpXX311\nzn0PHTrE7bffTnh4OPPmzaOxsZElS5awa9cu3n33XUwmUw+OvG/rSl0AgoOD+e1vf+vWpl+quub1\n119ny5Yt5OXlYbVaqa6u5q233uK6665j+fLlpKWlddpX55We0ZWatNF5pfvt37+f1tZWbrzxRqKj\nozl27BirVq1i1qxZvPbaa4wfP77Tvl5zrDjEI4qKihzp6emON954w9XW1NTkmDJliuO22247Y99X\nX33VYbVaHdu3b3e17dmzx5GZmel49tlne2rIfV5XavLcc8850tPTHXV1dT08yv7n2LFjjpqaGofD\n4XB8/PHHjvT0dMfGjRvPqe+vf/1rR05OjuPQoUOutsLCQkd6erojPz+/R8bbX3SlLvPnz3fk5ub2\n5PD6pc2bNzuam5vd2srLyx3Dhw93zJ8//4x9dV7pGV2pic4rvauxsdExbtw4x913333G7bzlWNEc\neA/56KOPMJlM3Hjjja62wMBAfvCDH7B582YOHz7cad81a9aQk5PDsGHDXG1paWmMHTuWf/zjHz06\n7r6sKzVp43A4OH78OA6HoyeH2q8MGDAAs9l8QX3Xrl3LlVdeSWxsrKtt3LhxpKSk6Fjpoq7UpU1r\nayvHjx/vphHJqFGjCAgIcGtLSUnhoosuoqys7Ix9dV7pGV2pSRudV3pHcHAwFouF+vr6M27nLceK\nAryH7Nixg9TUVEJDQ93aR4wYgcPhYMeOHR32s9vtlJaWMnz48HavXXzxxVRUVHDixIkeGXNfd6E1\n+W8TJ04kNzeX3NxcFixYQG1tbU8NV86iqqqKI0eOdHisjBgx4pzqKT2noaHBdayMHj2aJ554gubm\nZk8Pq89xOBx89913Z/xlS+eV3nUuNflvOq/0nOPHj1NTU8PevXt5+umn2bVr1xnvefOmY0Vz4D2k\nurra7apgm+joaIBOr/bW1tZis9lc253e1+FwUF1dTVJSUvcOuB+40JoAhIeHc8cdd5CdnY3JZGLj\nxo387W9/o6SkhPz8/HZXYKTntdWrs2PlyJEjtLa24ufn19tD6/eio6OZM2cOmZmZ2O121q9fz5tv\nvklZWRmvv/66p4fXp3zwwQdUVVUxb968TrfReaV3nUtNQOeV3vDoo4+yZs0aAEwmE7fccgv33ntv\np9t707GiAO8hTU1NHd5AFxgYCNDplai29o4O3La+TU1N3TXMfuVCawLwwx/+0O3rvLw8LrroIhYu\nXMj777/PTTfd1L2DlbM612Pl9L+4SM976KGH3L6eNm0asbGxLF68mMLCwjPeQCbnrqysjIULF5Kb\nm8uMGTM63U7nld5zrjUBnVd6w09/+lNuvvlmDh06xMqVK7HZbLS0tHT6y5E3HSuaQuMhQUFBtLS0\ntGtv++Fo+0E4XVu7zWbrtK/uUL8wF1qTztx6660EBwezYcOGbhmfnB8dK77lrrvuAtDx0k2qq6u5\n5557iIiIYNGiRRiNnZ/udaz0jvOpSWd0XuleVquV8ePHc8MNN7B48WK2b9/OggULOt3em44VBXgP\niY6O7nBKRnV1NQAxMTEd9ouMjCQgIMC13el9DQZDh3/akbO70Jp0xmg0EhsbS11dXbeMT85PW706\nO1YGDhyo6TNeJCoqCpPJpOOlGxw7doy5c+dy7NgxXn/99bOeE3Re6XnnW5PO6LzSc0wmE5MnT2bt\n2rWdXkX3pmNFAd5DMjIyKC8vp6Ghwa29qKjI9XpHjEYj6enpFBcXt3tt27ZtJCcnExwc3P0D7gcu\ntCadaWlp4eDBg11eqUMuTGxsLBaLpdNjJTMz0wOjks4cOnSIlpYWrQXfRc3Nzdx7771UVFTwyiuv\nMGTIkLP20XmlZ11ITTqj80rPampqwuFwtMsBbbzpWFGA95C8vDxaWlrIz893tdlsNlasWMGoUaNc\nN1NWVla2W2rq6quvZuvWrZSUlLja9u7dy8aNG8nLy+udHeiDulKTmpqadu+3ePFimpub+d73vtez\nAxcA9u3bx759+9zarrrqKj755BOqqqpcbRs2bKCiokLHSi85vS7Nzc0dLh350ksvATBhwoReG1tf\n09rayoMPPsjWrVtZtGgROTk5HW6n80rv6UpNdF7pOR19b48fP86aNWuIi4tj4MCBgHcfKwaHFhb1\nmAceeIB169bxwx/+kKSkJAoKCiguLubPf/4zubm5ANxxxx18+eWXlJaWuvodP36cmTNncuLECX70\nox/h5+fHm2++icPh4P3339dv5l1woTXJzs5m6tSppKenExAQwBdffMGaNWvIzc1l6dKl+PvrfvGu\naAt3ZWVlrF69mhtuuIGEhATCw8OZNWsWAFdeeSUAn3zyiavfwYMHue6664iMjGTWrFk0NjayePFi\n4uLitIpDN7iQuhw4cICZM2cybdo0hgwZ4lqFZsOGDUydOpVnnnnGMzvTB/z+979n6dKlTJo0iWuu\nucbttdDQUKZMmQLovNKbulITnVd6zuzZswkMDGTkyJFER0dz8OBBVqxYwaFDh3j66aeZOnUq4N3H\nigK8BzU3N/Pss8+yatUq6urqsFqt/PznP2fcuHGubTr64QHnn5sff/xxCgsLsdvtjB49mscee4zE\nxMTe3o0+5UJr8stf/pItW7Zw8OBBWlpaiI+PZ+rUqdxzzz26+asbWK3WDtvj4+NdwbCjAA+we/du\n/vCHP7B582ZMJhMTJ05kwYIFmqrRDS6kLvX19fzud7+jqKiIw4cPY7fbSUlJYebMmcyePVv3JXRB\n2/9NHfnvmui80nu6UhOdV3rO8uXLWblyJXv27KG+vp6wsDBycnK46667uOyyy1zbefOxogAvIiIi\nIuJDNAdeRERERMSHKMCLiIiIiPgQBXgRERERER+iAC8iIiIi4kMU4EVEREREfIgCvIiIiIiID1GA\nFxERERHxIQrwIiLitQ4cOIDVauX555/39FBERLyGnsMrItLPffHFF8yePdutLSAggJiYGC677DLm\nzJlDWlraBb33888/T2ZmpuuR8SIi0nUK8CIiAsC0adO4/PLLAWhubqa0tJT8/HzWrFnDqlWriI+P\nP+/3fOGFF5g5c6YCvIhIN1KAFxERAIYNG8aMGTPc2pKTk/n973/Pxx9/zJ133umZgYmIiBsFeBER\n6VRMTAwAJpPJ1fbWW2+xbt06du/ezdGjR4mMjGTMmDE8+OCDJCQkAM6565MnTwagoKCAgoICV//S\n0lLXvzdu3MiSJUsoKiqisbGRmJgYRo8ezcMPP4zFYnEby/r163nhhRfYtWsXERERTJ8+nYceegh/\nf53KRKR/0f96IiICwIkTJ6ipqQGcU2h27drFM888g9ls5qqrrnJtt2TJEnJycrjjjjuIjIxk165d\nLF++nI0bN7Jq1SrMZjMWi4Unn3ySX/ziF1xyySXcdNNN7T7vnXfe4Te/+Q2xsbHccsstxMfHU1lZ\nyfr166mqqnIL8J9++ilvv/02t9xyCzfccAPr1q1jyZIlREREcO+99/b8N0dExIsYHA6Hw9ODEBER\nz+noJtY2Q4cO5bnnnnO7ibWxsZGQkBC37TZs2MCdd97Jww8/zNy5c13tVquVmTNn8oc//MFt+0OH\nDjFlyhSSkpJ45513CA8Pd3vdbrdjNBpdV/KDg4NZvXq16wq/w+Fg+vTp1NbW8vnnn3dp/0VEfI2u\nwIuICAA333wzeXl5gPMK/J49e3jjjTe4++67Wbp0qesm1rbwbrfbaWhooKWlBavVSlhYGNu2bTun\nz/roo49oaWnh/vvvbxfeAYxG91WOJ0+e7ArvAAaDgdGjR/OXv/yFhoYGQkNDL2ifRUR8kQK8iIgA\nzhtWx40b5/p60qRJXHbZZdx000089dRTPPPMM4DzavtLL71EUVERzc3Nbu9RV1d3Tp9VUVEBQGZm\n5jltn5iY2K4tMjISgNraWgV4EelXFOBFRKRT2dnZhIWFsXHjRgC2bdvGj3/8Y5KSknjooYdISEgg\nKCgIg8HAvHnz6KlZmX5+fp2+ppmgItLfKMCLiMgZtba2YrPZAFi9ejWtra289tprblfFGxsbqa+v\nP+f3TElJAWDHjh2kpqZ263hFRPo649k3ERGR/qqwsJDGxkaysrKAzq+Ev/LKK9jt9nbtISEh1NbW\ntmvPy8vDZDLx4osvcvz48Xav66q6iEjndAVeREQAKCkpYeXKlQDYbDb27NnDu+++i8lk4sEHHwRg\nypQpvPnmm8ydO5ebb74Zk8lEYWEhpaWlmM3mdu+Zk5PDhg0bePXVVxk8eDAGg4Frr72WQYMG8eij\nj7Jw4UKmT5/OjBkziI+Pp6qqinXr1vH444+f8/x4EZH+RgFeREQA5/SY1atXA85VYCIjIxk/fjx3\n3303I0aMACAcimBgAAAAvUlEQVQ3N5fnn3+el156iUWLFhEYGMi4ceP4y1/+wqxZs9q9569//WsW\nLlzIyy+/TENDAwDXXnstALfddhtJSUksXryYZcuWYbPZiImJYezYsQwaNKiX9lpExPdoHXgRERER\nER+iOfAiIiIiIj5EAV5ERERExIcowIuIiIiI+BAFeBERERERH6IALyIiIiLiQxTgRURERER8iAK8\niIiIiIgPUYAXEREREfEhCvAiIiIiIj5EAV5ERERExIf8P+xWEQ4NMricAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hCKkKXa0AV5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "cae4ba2c-a013-490b-85cc-19923fb2e51d"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df1 = pd.read_csv(\"/content/drive/My Drive/Team restricted/Colab Notebooks/deal_val_data.csv\")\n",
        "\n",
        "df1_test = df1.to_dict('records')\n",
        "#print(df1_test)\n",
        "\n",
        "for i1 in range(433,df_bert_train_one['link'].count()):\n",
        "  df1_test.append(dict(df_bert_train_one.iloc[i1]) )\n",
        "\n",
        "df1_test = pd.DataFrame(df1_test)\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of test sentences: {:,}\\n'.format(df1_test.shape[0]))\n",
        "\n",
        "df1_test.head(14)\n",
        "\n",
        "#Creating the sentences and label lists\n",
        "sentences = df1_test.SENTENCE.values\n",
        "labels = df1_test.LABEL.values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of test sentences: 14\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJCqWsbp_SnO"
      },
      "source": [
        "\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                   )\n",
        "    \n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Pad our input tokens\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, \n",
        "                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask) \n",
        "\n",
        "# Convert to tensors.\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 30  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiJwm7hwN2Q5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "089d5da4-0fe1-4970-91ea-b47d5626b30b"
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 14 test sentences...\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VbhByONO4xC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "20741b51-21a1-420d-e337-fe70fdcd2713"
      },
      "source": [
        "print(predictions)\n",
        "print('-'*50)\n",
        "print(true_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([[-0.7572932 ,  0.3067823 ],\n",
            "       [ 0.87203777, -0.6979471 ],\n",
            "       [-1.25568   ,  0.79015476],\n",
            "       [-1.3608772 ,  0.79104084],\n",
            "       [-1.1120173 ,  0.43329406],\n",
            "       [ 0.9183744 , -0.7639485 ],\n",
            "       [ 1.2653387 , -0.90076286],\n",
            "       [ 0.5037765 , -0.4165206 ],\n",
            "       [-1.5173577 ,  0.8754852 ],\n",
            "       [ 1.6887057 , -1.2414652 ],\n",
            "       [-1.4310074 ,  0.8331612 ],\n",
            "       [-1.3179945 ,  0.8135978 ],\n",
            "       [-1.4408678 ,  0.92706996],\n",
            "       [-0.7572932 ,  0.3067823 ]], dtype=float32)]\n",
            "--------------------------------------------------\n",
            "[array([1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChyT6aZPPDVq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c6e8377d-4d26-4492-8e0f-b92bbede0045"
      },
      "source": [
        "print('Positive samples: %d of %d (%.2f%%)' % (df1_test.LABEL.sum(), len(df1_test.LABEL), (df1_test.LABEL.sum() / len(df1_test.LABEL) * 100.0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive samples: 9 of 14 (64.29%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeOsKMVuUNtK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "f4566d23-c301-4f11-feba-b520069e7009"
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "matthews_set = []\n",
        "\n",
        "# Evaluate each test batch using Matthew's correlation coefficient\n",
        "print('Calculating Matthews Corr. Coef. for each batch...')\n",
        "\n",
        "# For each input batch...\n",
        "for i in range(len(true_labels)):\n",
        "  \n",
        "  # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
        "  # and one column for \"1\"). Pick the label with the highest value and turn this\n",
        "  # in to a list of 0s and 1s.\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "  print(pred_labels_i)\n",
        "  print('-'*50)\n",
        "  print(true_labels[i])\n",
        "  # Calculate and store the coef for this batch.  \n",
        "  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n",
        "  matthews_set.append(matthews)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calculating Matthews Corr. Coef. for each batch...\n",
            "[1 0 1 1 1 0 0 0 1 0 1 1 1 1]\n",
            "--------------------------------------------------\n",
            "[1 0 1 0 1 1 0 0 1 0 1 1 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ci60U8geVtPX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a4f66f44-ad6e-4dbb-b535-9c12aa751f69"
      },
      "source": [
        "matthews_set"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6888888888888889]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWlFPtW1XHfP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a7642884-b14e-45db-db22-a47b3a7ce490"
      },
      "source": [
        "# Combine the predictions for each batch into a single list of 0s and 1s.\n",
        "flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
        "\n",
        "# Calculate the MCC\n",
        "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "\n",
        "print('MCC: %.3f' % mcc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MCC: 0.689\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKQhHEQmXinb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "122be97b-7acf-45f7-d410-31186c7c35df"
      },
      "source": [
        "import os\n",
        "\n",
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "\n",
        "output_dir = './model_save1/'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "# Good practice: save your training arguments together with the trained model\n",
        "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model to ./model_save1/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./model_save1/vocab.txt',\n",
              " './model_save1/special_tokens_map.json',\n",
              " './model_save1/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1pUWoy4YCFc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "63d5d547-58fe-499c-d6de-9b01c890a531"
      },
      "source": [
        "!ls -l --block-size=K ./model_save1/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 427968K\n",
            "-rw-r--r-- 1 root root      1K Jan 31 05:41 added_tokens.json\n",
            "-rw-r--r-- 1 root root      1K Jan 31 05:41 config.json\n",
            "-rw-r--r-- 1 root root 427719K Jan 31 05:41 pytorch_model.bin\n",
            "-rw-r--r-- 1 root root      1K Jan 31 05:41 special_tokens_map.json\n",
            "-rw-r--r-- 1 root root      1K Jan 31 05:41 tokenizer_config.json\n",
            "-rw-r--r-- 1 root root    227K Jan 31 05:41 vocab.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AX0fGWlYYYi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5dfeeaf3-c9ef-4689-ef98-a906e71ee1b0"
      },
      "source": [
        "!ls -l --block-size=M ./model_save1/pytorch_model.bin"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root root 418M Jan 31 05:41 ./model_save1/pytorch_model.bin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgsVHbQ4K2c2"
      },
      "source": [
        "# Copy the model files to a directory in your Google Drive.\n",
        "!cp -r ./model_save1/ \"./drive/My Drive/Team restricted/Colab Notebooks\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pr7Dj-Gn2ql3"
      },
      "source": [
        "from transformers import BertModel\n",
        "from transformers import BertTokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MY6iDhbYmdX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1e094f01-c2fe-4848-a79e-5d3fec47a25e"
      },
      "source": [
        "# Load a trained model and vocabulary that you have fine-tuned\n",
        "model = BertModel.from_pretrained('/content/drive/My Drive/Team restricted/Colab Notebooks/model_save1')\n",
        "tokenizer = BertTokenizer.from_pretrained('/content/drive/My Drive/Team restricted/Colab Notebooks/model_save1')\n",
        "\n",
        "# Copy the model to the GPU.\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbv7mvqa1L4w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "9ac9857b-4099-4fc0-e463-ecbb13181a71"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Fc-pTQbYvIi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}